{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CV Validation\n",
    "- scikit-learn의 module selection 내 모델 검증관련 기능 활용\n",
    "- 교차 검증 데이터 기반 검증 결과 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fishDF = pd.read_csv('../../DATA/fish.csv')\n",
    "irisDF = pd.read_csv('../../DATA/iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Species  Weight  Length  Diagonal   Height   Width\n",
      "0   Bream   242.0    25.4      30.0  11.5200  4.0200\n",
      "1   Bream   290.0    26.3      31.2  12.4800  4.3056\n",
      "2   Bream   340.0    26.5      31.1  12.3778  4.6961\n",
      "3   Bream   363.0    29.0      33.5  12.7300  4.4555\n",
      "4   Bream   430.0    29.0      34.0  12.4440  5.1340 (159, 6)\n",
      "--------------------------------------------------\n",
      "   sepal_length  sepal_width  petal_length  petal_width species\n",
      "0           5.1          3.5           1.4          0.2  setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa (150, 5)\n"
     ]
    }
   ],
   "source": [
    "# 1-2. Check Data\n",
    "print(fishDF.head(), fishDF.shape)\n",
    "print('-'*50)\n",
    "print(irisDF.head(), irisDF.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "2. Split feature and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    242.0\n",
      "1    290.0\n",
      "Name: Weight, dtype: float64\n",
      "   Length  Diagonal  Height   Width\n",
      "0    25.4      30.0   11.52  4.0200\n",
      "1    26.3      31.2   12.48  4.3056\n"
     ]
    }
   ],
   "source": [
    "fish_target = fishDF['Weight']\n",
    "# 특이사항 : species를 두고 Weight를 타깃으로 설정 -> 아니다 제거한다\n",
    "fish_feature = fishDF.drop(['Weight', 'Species'], axis=1)\n",
    "print(fish_target.head(2))\n",
    "print(fish_feature.head(2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    setosa\n",
      "1    setosa\n",
      "Name: species, dtype: object\n",
      "   sepal_length  sepal_width  petal_length  petal_width\n",
      "0           5.1          3.5           1.4          0.2\n",
      "1           4.9          3.0           1.4          0.2\n"
     ]
    }
   ],
   "source": [
    "iris_target = irisDF['species']\n",
    "iris_feature = irisDF.drop(['species'], axis=1)\n",
    "print(iris_target.head(2))\n",
    "print(iris_feature.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "3. Data Preprocessing\n",
    "1) feature scaling\n",
    "2) data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Split data into train and val\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1) fish -> train, test : Regression\n",
    "fish_X_train, fish_X_test, fish_y_train, fish_y_test = train_test_split(fish_feature,\n",
    "                                                                        fish_target, \n",
    "                                                                        test_size=0.2, random_state=5)\n",
    "\n",
    "# 2) iris -> train, test : Classification\n",
    "iris_X_train, iris_X_test, iris_y_train, iris_y_test = train_test_split(iris_feature,\n",
    "                                                                        iris_target,\n",
    "                                                                        test_size=0.2, random_state=5,\n",
    "                                                                        stratify=iris_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "fish_scaler = StandardScaler()\n",
    "fish_X_train_scaled = fish_scaler.fit_transform(fish_X_train)\n",
    "fish_X_test_scaled = fish_scaler.transform(fish_X_test)\n",
    "\n",
    "iris_scaler = StandardScaler()\n",
    "iris_X_train_scaled = iris_scaler.fit_transform(iris_X_train)\n",
    "iris_X_test_scaled = iris_scaler.transform(iris_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "4. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Set Model instance\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>estimator</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.135994</td>\n",
       "      <td>0.004013</td>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>0.921047</td>\n",
       "      <td>0.874264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>0.843854</td>\n",
       "      <td>0.887794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>0.885924</td>\n",
       "      <td>0.880611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>0.646720</td>\n",
       "      <td>0.902975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>0.790319</td>\n",
       "      <td>0.898336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time           estimator  test_score  train_score\n",
       "0  0.135994    0.004013  LinearRegression()    0.921047     0.874264\n",
       "1  0.000000    0.000000  LinearRegression()    0.843854     0.887794\n",
       "2  0.000000    0.002397  LinearRegression()    0.885924     0.880611\n",
       "3  0.002023    0.000000  LinearRegression()    0.646720     0.902975\n",
       "4  0.000000    0.000000  LinearRegression()    0.790319     0.898336"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Predict Weight of fish\n",
    "# 1) Use CV\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Return every evaluations\n",
    "# - cv= : number of split\n",
    "# - return_train_score : As literally\n",
    "result = cross_validate(lr_model, fish_X_train_scaled, fish_y_train, \n",
    "                        return_estimator=True,\n",
    "                        return_train_score=True, cv=5)\n",
    "resultDF = pd.DataFrame(result)\n",
    "resultDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 373.98470744 -159.77931033   90.53431501   50.22123874]\n",
      "408.522509249702\n"
     ]
    }
   ],
   "source": [
    "# best model\n",
    "best_model = resultDF.iloc[0]['estimator']\n",
    "print(best_model.coef_)\n",
    "print(best_model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92104683, 0.84385378, 0.88592423, 0.64671954, 0.79031905])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If only needed Scores: cross_val_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(lr_model, fish_X_train_scaled, fish_y_train, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.09792517e+01,  9.85612151e+01,  3.87029719e+02,  1.13011547e+02,\n",
       "        6.81676563e+02,  2.82456988e+02,  5.34379642e+02,  3.61848302e+02,\n",
       "        6.12934598e+02,  1.70756130e+02,  5.53222970e+02,  1.69433076e+01,\n",
       "       -2.53895688e+01,  8.14926155e+02,  6.97225129e+01,  3.38157931e+02,\n",
       "        4.76306355e+02,  7.67659158e+02,  6.55686457e+02,  1.80300946e+02,\n",
       "        8.45315559e+02,  2.92145322e+02,  6.08539351e+02,  9.02782406e+02,\n",
       "        6.99788981e+02,  9.40316876e+02,  7.47628344e+02,  3.28419355e+02,\n",
       "        7.89622699e+02,  9.09130831e+02, -1.98986854e+02,  1.81089559e+02,\n",
       "        6.36731679e+02, -1.09209894e+02,  3.57087822e+02,  7.88250361e+02,\n",
       "        3.25180589e+02,  6.56473977e+02, -2.37032025e+02,  4.55882834e+01,\n",
       "        9.57130255e+01, -2.10830505e+02,  1.28969696e+02, -2.21199132e+02,\n",
       "       -1.10282630e+02,  6.39911566e+02,  2.12288357e+02,  2.41098815e+02,\n",
       "        2.61932359e+02, -2.58301758e+02,  2.93250859e+01,  8.87950700e+02,\n",
       "        2.46460034e+02,  5.55564851e+02,  6.71006008e+02,  7.04637891e+02,\n",
       "        2.29677895e+02,  8.49746634e+02,  7.24031103e+02, -5.70994192e+01,\n",
       "        2.22728797e+02,  9.41173359e+02,  5.25995612e+02,  7.74853524e+02,\n",
       "        2.17941892e+02,  5.74873742e+02,  2.17397906e+02,  5.98772429e+02,\n",
       "        8.13391991e+02,  1.93602150e+02,  2.00834243e+02,  8.85719610e+02,\n",
       "        7.94930726e+02,  4.91188615e+02,  1.11555582e+02,  2.15505969e+02,\n",
       "        4.55682558e+02,  3.27230281e+02, -2.54736199e+02,  2.14499169e+02,\n",
       "        4.32295967e+02,  5.29619314e+02,  3.11672406e-01, -2.77216256e+02,\n",
       "        6.55329442e+02,  4.59082390e+02,  3.18928562e+02, -2.27015547e+02,\n",
       "        7.74464230e+02, -2.40117603e+02,  6.37572206e+02,  6.23647648e+02,\n",
       "        1.58228119e+02,  5.16093336e+02,  8.12222679e+01,  2.27883952e+02,\n",
       "        3.92943741e+02,  8.47396913e+02, -2.24559795e+02,  3.94415997e+02,\n",
       "        6.81290262e+02,  5.82109256e+02,  3.57665080e+02,  5.94846811e+02,\n",
       "        5.14375584e+02,  3.62255513e+02,  3.41676651e+02,  1.69523793e+02,\n",
       "        3.79453524e+02,  5.85425213e+02,  8.26535922e+02,  8.65537588e+02,\n",
       "        2.04176403e+02,  8.17998531e+02,  2.25074947e+02,  2.07081163e+02,\n",
       "        7.19337633e+02,  1.31467393e+02,  6.85638198e+02,  9.06351710e+02,\n",
       "        4.79431463e+02,  7.01957458e+02,  5.22269464e+02, -4.60942099e+01,\n",
       "        1.04657155e+03,  8.10571851e+02,  2.69273973e+02])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If only needed Predict : cross_val_predict\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "predictions = cross_val_predict(lr_model, fish_X_train_scaled, fish_y_train, cv=5)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tunning : GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결정 경계선\n",
    "# - 서포터 벡터 : 선을 긋는 데 도와준 요소\n",
    "# - 그리고 수많은 파라미터..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. set module\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model\n",
    "est = LogisticRegression(max_iter=10000, solver='liblinear')\n",
    "\n",
    "# Set params; \n",
    "params = {'penalty': ['l1', 'l2', 'elasticnet'], \n",
    "          'solver' : ['lbfgs', 'auto', 'liblinear', 'newton_cg', 'lbfgs', 'sag', 'saga']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set GridSearchCV\n",
    "gscv = GridSearchCV(est, param_grid=params, return_train_score=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "#### 데이터에 적합한 모델 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import all_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AdaBoostClassifier', sklearn.ensemble._weight_boosting.AdaBoostClassifier),\n",
       " ('BaggingClassifier', sklearn.ensemble._bagging.BaggingClassifier),\n",
       " ('BernoulliNB', sklearn.naive_bayes.BernoulliNB),\n",
       " ('CalibratedClassifierCV', sklearn.calibration.CalibratedClassifierCV),\n",
       " ('CategoricalNB', sklearn.naive_bayes.CategoricalNB),\n",
       " ('ClassifierChain', sklearn.multioutput.ClassifierChain),\n",
       " ('ComplementNB', sklearn.naive_bayes.ComplementNB),\n",
       " ('DecisionTreeClassifier', sklearn.tree._classes.DecisionTreeClassifier),\n",
       " ('DummyClassifier', sklearn.dummy.DummyClassifier),\n",
       " ('ExtraTreeClassifier', sklearn.tree._classes.ExtraTreeClassifier),\n",
       " ('ExtraTreesClassifier', sklearn.ensemble._forest.ExtraTreesClassifier),\n",
       " ('GaussianNB', sklearn.naive_bayes.GaussianNB),\n",
       " ('GaussianProcessClassifier',\n",
       "  sklearn.gaussian_process._gpc.GaussianProcessClassifier),\n",
       " ('GradientBoostingClassifier',\n",
       "  sklearn.ensemble._gb.GradientBoostingClassifier),\n",
       " ('HistGradientBoostingClassifier',\n",
       "  sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier),\n",
       " ('KNeighborsClassifier',\n",
       "  sklearn.neighbors._classification.KNeighborsClassifier),\n",
       " ('LabelPropagation',\n",
       "  sklearn.semi_supervised._label_propagation.LabelPropagation),\n",
       " ('LabelSpreading', sklearn.semi_supervised._label_propagation.LabelSpreading),\n",
       " ('LinearDiscriminantAnalysis',\n",
       "  sklearn.discriminant_analysis.LinearDiscriminantAnalysis),\n",
       " ('LinearSVC', sklearn.svm._classes.LinearSVC),\n",
       " ('LogisticRegression', sklearn.linear_model._logistic.LogisticRegression),\n",
       " ('LogisticRegressionCV', sklearn.linear_model._logistic.LogisticRegressionCV),\n",
       " ('MLPClassifier',\n",
       "  sklearn.neural_network._multilayer_perceptron.MLPClassifier),\n",
       " ('MultiOutputClassifier', sklearn.multioutput.MultiOutputClassifier),\n",
       " ('MultinomialNB', sklearn.naive_bayes.MultinomialNB),\n",
       " ('NearestCentroid', sklearn.neighbors._nearest_centroid.NearestCentroid),\n",
       " ('NuSVC', sklearn.svm._classes.NuSVC),\n",
       " ('OneVsOneClassifier', sklearn.multiclass.OneVsOneClassifier),\n",
       " ('OneVsRestClassifier', sklearn.multiclass.OneVsRestClassifier),\n",
       " ('OutputCodeClassifier', sklearn.multiclass.OutputCodeClassifier),\n",
       " ('PassiveAggressiveClassifier',\n",
       "  sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier),\n",
       " ('Perceptron', sklearn.linear_model._perceptron.Perceptron),\n",
       " ('QuadraticDiscriminantAnalysis',\n",
       "  sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis),\n",
       " ('RadiusNeighborsClassifier',\n",
       "  sklearn.neighbors._classification.RadiusNeighborsClassifier),\n",
       " ('RandomForestClassifier', sklearn.ensemble._forest.RandomForestClassifier),\n",
       " ('RidgeClassifier', sklearn.linear_model._ridge.RidgeClassifier),\n",
       " ('RidgeClassifierCV', sklearn.linear_model._ridge.RidgeClassifierCV),\n",
       " ('SGDClassifier', sklearn.linear_model._stochastic_gradient.SGDClassifier),\n",
       " ('SVC', sklearn.svm._classes.SVC),\n",
       " ('StackingClassifier', sklearn.ensemble._stacking.StackingClassifier),\n",
       " ('VotingClassifier', sklearn.ensemble._voting.VotingClassifier)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_estimators('classifier')    # show every Classifier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier()\n",
      "BaggingClassifier()\n",
      "BernoulliNB()\n",
      "CalibratedClassifierCV()\n",
      "Negative values in data passed to CategoricalNB (input X)\n",
      "__init__() missing 1 required positional argument: 'base_estimator'\n",
      "Negative values in data passed to ComplementNB (input X)\n",
      "DecisionTreeClassifier()\n",
      "DummyClassifier()\n",
      "ExtraTreeClassifier()\n",
      "ExtraTreesClassifier()\n",
      "GaussianNB()\n",
      "GaussianProcessClassifier()\n",
      "GradientBoostingClassifier()\n",
      "HistGradientBoostingClassifier()\n",
      "KNeighborsClassifier()\n",
      "LabelPropagation()\n",
      "LabelSpreading()\n",
      "LinearDiscriminantAnalysis()\n",
      "LinearSVC()\n",
      "LogisticRegression()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wjs31\\.conda\\envs\\EXAM_MML\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wjs31\\.conda\\envs\\EXAM_MML\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegressionCV()\n",
      "MLPClassifier()\n",
      "__init__() missing 1 required positional argument: 'estimator'\n",
      "Negative values in data passed to MultinomialNB (input X)\n",
      "NearestCentroid()\n",
      "NuSVC()\n",
      "__init__() missing 1 required positional argument: 'estimator'\n",
      "__init__() missing 1 required positional argument: 'estimator'\n",
      "__init__() missing 1 required positional argument: 'estimator'\n",
      "PassiveAggressiveClassifier()\n",
      "Perceptron()\n",
      "QuadraticDiscriminantAnalysis()\n",
      "RadiusNeighborsClassifier()\n",
      "RandomForestClassifier()\n",
      "RidgeClassifier()\n",
      "RidgeClassifierCV()\n",
      "SGDClassifier()\n",
      "SVC()\n",
      "__init__() missing 1 required positional argument: 'estimators'\n",
      "__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wjs31\\.conda\\envs\\EXAM_MML\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# def 각\n",
    "\n",
    "models = all_estimators(type_filter='classifier')\n",
    "\n",
    "for name, model in models:\n",
    "    try:\n",
    "        print(model().fit(iris_X_train_scaled, iris_y_train))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    \n",
    "# ValueError : \n",
    "# 1) try, except\n",
    "# 2) \n",
    "# - 쭉 가다가 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EXAM_MML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
