{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< 3월 13일 과제 >  \n",
    "1. winequality-white.csv\n",
    "2. 딥러닝 적용해보기\n",
    "3. 모델 : LinearRegression - 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4898 entries, 0 to 4897\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         4898 non-null   float64\n",
      " 1   volatile acidity      4898 non-null   float64\n",
      " 2   citric acid           4898 non-null   float64\n",
      " 3   residual sugar        4898 non-null   float64\n",
      " 4   chlorides             4898 non-null   float64\n",
      " 5   free sulfur dioxide   4898 non-null   float64\n",
      " 6   total sulfur dioxide  4898 non-null   float64\n",
      " 7   density               4898 non-null   float64\n",
      " 8   pH                    4898 non-null   float64\n",
      " 9   sulphates             4898 non-null   float64\n",
      " 10  alcohol               4898 non-null   float64\n",
      " 11  quality               4898 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 459.3 KB\n"
     ]
    }
   ],
   "source": [
    "# Data Load\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "wine_df = pd.read_csv('winequality-white.csv', sep=';')\n",
    "wine_df.info() # data 깔끔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복 확인\n",
    "wine_df.duplicated().sum()   # 937\n",
    "wine_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quality                 1.000000\n",
       "alcohol                 0.462869\n",
       "density                 0.337805\n",
       "chlorides               0.217739\n",
       "volatile acidity        0.190678\n",
       "total sulfur dioxide    0.183356\n",
       "fixed acidity           0.124636\n",
       "pH                      0.123829\n",
       "residual sugar          0.117339\n",
       "sulphates               0.053200\n",
       "free sulfur dioxide     0.010507\n",
       "citric acid             0.007065\n",
       "Name: quality, dtype: float64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 피처 지정\n",
    "wine_df.corr().abs().quality.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.21233367843325224\n"
     ]
    }
   ],
   "source": [
    "# Split\n",
    "feature = wine_df[['alcohol', 'density']]\n",
    "target = wine_df['quality']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature, target, test_size=0.2, random_state=11)\n",
    "\n",
    "# Modeling\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_model = LinearRegression()\n",
    "lin_model.fit(X_train, y_train)\n",
    "print('Test :', lin_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.8</td>\n",
       "      <td>1.00100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.5</td>\n",
       "      <td>0.99400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1</td>\n",
       "      <td>0.99510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.9</td>\n",
       "      <td>0.99560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.6</td>\n",
       "      <td>0.99490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.99114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>9.6</td>\n",
       "      <td>0.99490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>9.4</td>\n",
       "      <td>0.99254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>12.8</td>\n",
       "      <td>0.98869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>11.8</td>\n",
       "      <td>0.98941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3961 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      alcohol  density\n",
       "0         8.8  1.00100\n",
       "1         9.5  0.99400\n",
       "2        10.1  0.99510\n",
       "3         9.9  0.99560\n",
       "6         9.6  0.99490\n",
       "...       ...      ...\n",
       "4893     11.2  0.99114\n",
       "4894      9.6  0.99490\n",
       "4895      9.4  0.99254\n",
       "4896     12.8  0.98869\n",
       "4897     11.8  0.98941\n",
       "\n",
       "[3961 rows x 2 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn               # 인공신경망 층 관련 모듈\n",
    "import torch.optim as optim         # 인공신경망 관련 함수\n",
    "import torch.nn.functional as F     # 최적화 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2b7a0d43810>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(718)      # 랜덤 시드 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform train, test data as tensor type\n",
    "X_train_ten = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_ten = torch.tensor(y_train.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q. 근데 왜 굳이 split을 할까요? cost로 학습하는 거면 모두 넣어도 상관 없지 않을까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3168, 2]) 2 tensor([[ 9.5000,  0.9927],\n",
      "        [10.6000,  0.9938],\n",
      "        [ 8.7000,  1.0001],\n",
      "        ...,\n",
      "        [ 9.5000,  0.9958],\n",
      "        [ 9.6000,  0.9964],\n",
      "        [12.2000,  0.9908]])\n",
      "torch.Size([3168]) 1 tensor([5., 6., 5.,  ..., 5., 6., 6.])\n"
     ]
    }
   ],
   "source": [
    "# shape, ndim, x_train 확인\n",
    "print(X_train_ten.shape, X_train_ten.ndim, X_train_ten)\n",
    "print(y_train_ten.shape, y_train_ten.ndim, y_train_ten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 학습 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W : tensor([[0.],\n",
      "        [0.]], requires_grad=True), b : tensor([0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Reset Weight, b value\n",
    "W = torch.zeros((2,1), requires_grad=True)  \n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "print(f'W : {W}, b : {b}')\n",
    "# requires_grad= : 학습을 통해 값이 계속 변하는 변수임을 의미\n",
    "# (If autograd should record operations on the returned tensor.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set SGD : Updata W, b\n",
    "# - W, b, learning rate\n",
    "optimizer = optim.SGD([W, b], lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 학습 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_ten.matmul(W)+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "W : tensor([[-123.6203],\n",
      "        [ -11.6253]]), b : tensor([-11.6976])\n",
      "1\n",
      "W : tensor([[161.0579],\n",
      "        [ 14.7972]]), b : tensor([14.8958])\n",
      "2\n",
      "W : tensor([[-209.6872],\n",
      "        [ -19.6135]]), b : tensor([-19.7374])\n",
      "3\n",
      "W : tensor([[273.1455],\n",
      "        [ 25.2008]]), b : tensor([25.3667])\n",
      "4\n",
      "W : tensor([[-355.6624],\n",
      "        [ -33.1621]]), b : tensor([-33.3736])\n",
      "5\n",
      "W : tensor([[463.2532],\n",
      "        [ 42.8459]]), b : tensor([43.1258])\n",
      "6\n",
      "W : tensor([[-603.2456],\n",
      "        [ -56.1415]]), b : tensor([-56.5015])\n",
      "7\n",
      "W : tensor([[785.6885],\n",
      "        [ 72.7730]]), b : tensor([73.2464])\n",
      "8\n",
      "W : tensor([[-1023.1630],\n",
      "        [  -95.1161]]), b : tensor([-95.7281])\n",
      "9\n",
      "W : tensor([[1332.5594],\n",
      "        [ 123.5312]]), b : tensor([124.3327])\n",
      "10\n",
      "W : tensor([[-1735.3696],\n",
      "        [ -161.2196]]), b : tensor([-162.2591])\n",
      "11\n",
      "W : tensor([[2260.0881],\n",
      "        [ 209.6202]]), b : tensor([210.9784])\n",
      "12\n",
      "W : tensor([[-2943.3193],\n",
      "        [ -273.3356]]), b : tensor([-275.1000])\n",
      "13\n",
      "W : tensor([[3833.2378],\n",
      "        [ 355.6328]]), b : tensor([357.9350])\n",
      "14\n",
      "W : tensor([[-4992.0801],\n",
      "        [ -463.4919]]), b : tensor([-466.4857])\n",
      "15\n",
      "W : tensor([[6501.4019],\n",
      "        [ 603.2794]]), b : tensor([607.1827])\n",
      "16\n",
      "W : tensor([[-8466.9102],\n",
      "        [ -786.0093]]), b : tensor([-791.0884])\n",
      "17\n",
      "W : tensor([[11026.7764],\n",
      "        [ 1023.3036]]), b : tensor([1029.9227])\n",
      "18\n",
      "W : tensor([[-14360.4434],\n",
      "        [ -1333.0193]]), b : tensor([-1341.6351])\n",
      "19\n",
      "W : tensor([[18702.1074],\n",
      "        [ 1735.6921]]), b : tensor([1746.9171])\n",
      "20\n",
      "W : tensor([[-24356.2676],\n",
      "        [ -2260.7844]]), b : tensor([-2275.3984])\n",
      "21\n",
      "W : tensor([[31719.9766],\n",
      "        [ 2943.9504]]), b : tensor([2962.9873])\n",
      "22\n",
      "W : tensor([[-41309.8359],\n",
      "        [ -3834.3354]]), b : tensor([-3859.1233])\n",
      "23\n",
      "W : tensor([[53799.1250],\n",
      "        [ 4993.2334]]), b : tensor([5025.5200])\n",
      "24\n",
      "W : tensor([[-70064.1719],\n",
      "        [ -6503.1772]]), b : tensor([-6545.2217])\n",
      "25\n",
      "W : tensor([[91246.7734],\n",
      "        [ 8468.9512]]), b : tensor([8523.7090])\n",
      "26\n",
      "W : tensor([[-118833.3906],\n",
      "        [ -11029.7109]]), b : tensor([-11101.0186])\n",
      "27\n",
      "W : tensor([[154760.4219],\n",
      "        [ 14363.9883]]), b : tensor([14456.8613])\n",
      "28\n",
      "W : tensor([[-201549.1875],\n",
      "        [ -18707.0000]]), b : tensor([-18827.9473])\n",
      "29\n",
      "W : tensor([[262483.7500],\n",
      "        [ 24362.3633]]), b : tensor([24519.8828])\n",
      "30\n",
      "W : tensor([[-341840.5625],\n",
      "        [ -31728.1875]]), b : tensor([-31933.3262])\n",
      "31\n",
      "W : tensor([[445189.5000],\n",
      "        [ 41320.2578]]), b : tensor([41587.4180])\n",
      "32\n",
      "W : tensor([[-579784.0000],\n",
      "        [ -53812.9766]]), b : tensor([-54160.9023])\n",
      "33\n",
      "W : tensor([[755070.6250],\n",
      "        [ 70081.9688]]), b : tensor([70535.0859])\n",
      "34\n",
      "W : tensor([[-983351.5000],\n",
      "        [ -91270.2266]]), b : tensor([-91860.3438])\n",
      "35\n",
      "W : tensor([[1280648.8750],\n",
      "        [ 118863.6562]]), b : tensor([119632.1953])\n",
      "36\n",
      "W : tensor([[-1667828.2500],\n",
      "        [ -154800.1562]]), b : tensor([-155801.0312])\n",
      "37\n",
      "W : tensor([[2172063.5000],\n",
      "        [ 201600.6250]]), b : tensor([202904.0938])\n",
      "38\n",
      "W : tensor([[-2828744.5000],\n",
      "        [ -262550.9688]]), b : tensor([-264248.5312])\n",
      "39\n",
      "W : tensor([[3683960.7500],\n",
      "        [ 341927.8125]]), b : tensor([344138.5625])\n",
      "40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W : tensor([[-4797735.0000],\n",
      "        [ -445303.4062]]), b : tensor([-448182.5625])\n",
      "41\n",
      "W : tensor([[6248237.],\n",
      "        [ 579932.]]), b : tensor([583681.5000])\n",
      "42\n",
      "W : tensor([[-8137270.0000],\n",
      "        [ -755263.5000]]), b : tensor([-760146.6875])\n",
      "43\n",
      "W : tensor([[10597415.0000],\n",
      "        [  983602.2500]]), b : tensor([989961.8750])\n",
      "44\n",
      "W : tensor([[-13801336.0000],\n",
      "        [ -1280975.6250]]), b : tensor([-1289258.])\n",
      "45\n",
      "W : tensor([[17973902.0000],\n",
      "        [ 1668253.1250]]), b : tensor([1679039.2500])\n",
      "46\n",
      "W : tensor([[-23407960.],\n",
      "        [ -2172618.]]), b : tensor([-2186665.])\n",
      "47\n",
      "W : tensor([[30484898.0000],\n",
      "        [ 2829465.5000]]), b : tensor([2847759.5000])\n",
      "48\n",
      "W : tensor([[-39701416.0000],\n",
      "        [ -3684899.5000]]), b : tensor([-3708724.])\n",
      "49\n",
      "W : tensor([[51704368.],\n",
      "        [ 4798958.]]), b : tensor([4829985.])\n",
      "50\n",
      "W : tensor([[-67336176.],\n",
      "        [ -6249828.]]), b : tensor([-6290236.5000])\n",
      "51\n",
      "W : tensor([[87693968.],\n",
      "        [ 8139344.]]), b : tensor([8191969.])\n",
      "52\n",
      "W : tensor([[-1.1421e+08],\n",
      "        [-1.0600e+07]]), b : tensor([-10668653.])\n",
      "53\n",
      "W : tensor([[1.4873e+08],\n",
      "        [1.3805e+07]]), b : tensor([13894111.])\n",
      "54\n",
      "W : tensor([[-1.9370e+08],\n",
      "        [-1.7978e+07]]), b : tensor([-18094724.])\n",
      "55\n",
      "W : tensor([[2.5226e+08],\n",
      "        [2.3414e+07]]), b : tensor([23565314.])\n",
      "56\n",
      "W : tensor([[-3.2853e+08],\n",
      "        [-3.0493e+07]]), b : tensor([-30689832.])\n",
      "57\n",
      "W : tensor([[4.2786e+08],\n",
      "        [3.9712e+07]]), b : tensor([39968304.])\n",
      "58\n",
      "W : tensor([[-5.5721e+08],\n",
      "        [-5.1718e+07]]), b : tensor([-52051972.])\n",
      "59\n",
      "W : tensor([[7.2567e+08],\n",
      "        [6.7353e+07]]), b : tensor([67788896.])\n",
      "60\n",
      "W : tensor([[-9.4506e+08],\n",
      "        [-8.7716e+07]]), b : tensor([-88283552.])\n",
      "61\n",
      "W : tensor([[1.2308e+09],\n",
      "        [1.1424e+08]]), b : tensor([1.1497e+08])\n",
      "62\n",
      "W : tensor([[-1.6029e+09],\n",
      "        [-1.4877e+08]]), b : tensor([-1.4973e+08])\n",
      "63\n",
      "W : tensor([[2.0875e+09],\n",
      "        [1.9375e+08]]), b : tensor([1.9500e+08])\n",
      "64\n",
      "W : tensor([[-2.7186e+09],\n",
      "        [-2.5233e+08]]), b : tensor([-2.5396e+08])\n",
      "65\n",
      "W : tensor([[3.5405e+09],\n",
      "        [3.2861e+08]]), b : tensor([3.3074e+08])\n",
      "66\n",
      "W : tensor([[-4.6109e+09],\n",
      "        [-4.2797e+08]]), b : tensor([-4.3073e+08])\n",
      "67\n",
      "W : tensor([[6.0050e+09],\n",
      "        [5.5735e+08]]), b : tensor([5.6096e+08])\n",
      "68\n",
      "W : tensor([[-7.8204e+09],\n",
      "        [-7.2586e+08]]), b : tensor([-7.3055e+08])\n",
      "69\n",
      "W : tensor([[1.0185e+10],\n",
      "        [9.4531e+08]]), b : tensor([9.5142e+08])\n",
      "70\n",
      "W : tensor([[-1.3264e+10],\n",
      "        [-1.2311e+09]]), b : tensor([-1.2391e+09])\n",
      "71\n",
      "W : tensor([[1.7274e+10],\n",
      "        [1.6033e+09]]), b : tensor([1.6137e+09])\n",
      "72\n",
      "W : tensor([[-2.2497e+10],\n",
      "        [-2.0880e+09]]), b : tensor([-2.1015e+09])\n",
      "73\n",
      "W : tensor([[2.9298e+10],\n",
      "        [2.7193e+09]]), b : tensor([2.7369e+09])\n",
      "74\n",
      "W : tensor([[-3.8156e+10],\n",
      "        [-3.5414e+09]]), b : tensor([-3.5643e+09])\n",
      "75\n",
      "W : tensor([[4.9691e+10],\n",
      "        [4.6121e+09]]), b : tensor([4.6419e+09])\n",
      "76\n",
      "W : tensor([[-6.4714e+10],\n",
      "        [-6.0065e+09]]), b : tensor([-6.0453e+09])\n",
      "77\n",
      "W : tensor([[8.4280e+10],\n",
      "        [7.8224e+09]]), b : tensor([7.8730e+09])\n",
      "78\n",
      "W : tensor([[-1.0976e+11],\n",
      "        [-1.0187e+10]]), b : tensor([-1.0253e+10])\n",
      "79\n",
      "W : tensor([[1.4294e+11],\n",
      "        [1.3267e+10]]), b : tensor([1.3353e+10])\n",
      "80\n",
      "W : tensor([[-1.8616e+11],\n",
      "        [-1.7279e+10]]), b : tensor([-1.7390e+10])\n",
      "81\n",
      "W : tensor([[2.4244e+11],\n",
      "        [2.2502e+10]]), b : tensor([2.2648e+10])\n",
      "82\n",
      "W : tensor([[-3.1574e+11],\n",
      "        [-2.9305e+10]]), b : tensor([-2.9495e+10])\n",
      "83\n",
      "W : tensor([[4.1120e+11],\n",
      "        [3.8165e+10]]), b : tensor([3.8412e+10])\n",
      "84\n",
      "W : tensor([[-5.3552e+11],\n",
      "        [-4.9704e+10]]), b : tensor([-5.0025e+10])\n",
      "85\n",
      "W : tensor([[6.9742e+11],\n",
      "        [6.4731e+10]]), b : tensor([6.5150e+10])\n",
      "86\n",
      "W : tensor([[-9.0827e+11],\n",
      "        [-8.4301e+10]]), b : tensor([-8.4846e+10])\n",
      "87\n",
      "W : tensor([[1.1829e+12],\n",
      "        [1.0979e+11]]), b : tensor([1.1050e+11])\n",
      "88\n",
      "W : tensor([[-1.5405e+12],\n",
      "        [-1.4298e+11]]), b : tensor([-1.4390e+11])\n",
      "89\n",
      "W : tensor([[2.0062e+12],\n",
      "        [1.8621e+11]]), b : tensor([1.8741e+11])\n",
      "90\n",
      "W : tensor([[-2.6128e+12],\n",
      "        [-2.4250e+11]]), b : tensor([-2.4407e+11])\n",
      "91\n",
      "W : tensor([[3.4027e+12],\n",
      "        [3.1582e+11]]), b : tensor([3.1786e+11])\n",
      "92\n",
      "W : tensor([[-4.4314e+12],\n",
      "        [-4.1130e+11]]), b : tensor([-4.1396e+11])\n",
      "93\n",
      "W : tensor([[5.7712e+12],\n",
      "        [5.3565e+11]]), b : tensor([5.3911e+11])\n",
      "94\n",
      "W : tensor([[-7.5160e+12],\n",
      "        [-6.9760e+11]]), b : tensor([-7.0211e+11])\n",
      "95\n",
      "W : tensor([[9.7883e+12],\n",
      "        [9.0850e+11]]), b : tensor([9.1437e+11])\n",
      "96\n",
      "W : tensor([[-1.2748e+13],\n",
      "        [-1.1832e+12]]), b : tensor([-1.1908e+12])\n",
      "97\n",
      "W : tensor([[1.6602e+13],\n",
      "        [1.5409e+12]]), b : tensor([1.5508e+12])\n",
      "98\n",
      "W : tensor([[-2.1621e+13],\n",
      "        [-2.0067e+12]]), b : tensor([-2.0197e+12])\n",
      "99\n",
      "W : tensor([[2.8157e+13],\n",
      "        [2.6134e+12]]), b : tensor([2.6303e+12])\n",
      "100\n",
      "W : tensor([[-3.6670e+13],\n",
      "        [-3.4035e+12]]), b : tensor([-3.4255e+12])\n",
      "tensor([[2.0743e+11],\n",
      "        [1.9252e+10]], requires_grad=True)\n",
      "\n",
      "tensor([1.9377e+10], requires_grad=True)\n",
      "\n",
      "tensor(2.9709e+24, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs+1):\n",
    "    print(epoch)\n",
    "    # 1. function\n",
    "    y_pred = X_train_ten.matmul(W) + b\n",
    "    \n",
    "    # cost\n",
    "    cost = torch.mean((y_pred - y_train_ten)**2)\n",
    "    \n",
    "    # Upgrade H(x) by cost\n",
    "    optimizer.zero_grad()        # gradient 초기화\n",
    "    cost.backward()              # cost 미분\n",
    "    optimizer.step()             # Update W, b\n",
    "    print(f'W : {W.grad}, b : {b.grad}')\n",
    "    \n",
    "    \n",
    "    # if epoch % 10 == 0:\n",
    "    #     print(f'Epoch : {epoch},') # W: {W.item()}, b: {b.item()}, Cost: {cost.item()}')\n",
    "\n",
    "print(W, b, cost, sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.9995e+11], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W[0]*1 + W[1]*10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "419327639552.0"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_tensor = torch.tensor([[1.0, 10.0]], dtype=torch.float32)\n",
    "predic = pred_tensor.matmul(W) + b\n",
    "predic.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch_PY38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
