{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight initialization\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(8, 4)\n",
    "        self.fc2 = nn.Linear(4, 2)\n",
    "        self.fc3 = nn.Linear(2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    # 강사님 코드\n",
    "    # def forward(self, x):\n",
    "    #     return self.fc3(self.fc2(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Model instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0737, -0.2465,  0.1391, -0.1397,  0.1616, -0.0875, -0.2610,  0.3344],\n",
      "        [-0.1374, -0.0259, -0.3003, -0.2538,  0.1562, -0.1993,  0.1338, -0.0757],\n",
      "        [-0.0462,  0.3318, -0.2704,  0.3306, -0.1283, -0.0903, -0.1130,  0.2921],\n",
      "        [ 0.2102, -0.0504, -0.2849, -0.1653, -0.2552, -0.1747, -0.3002,  0.0139]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Create Model Instance\n",
    "model = Net()\n",
    "\n",
    "# Check attributes\n",
    "print(model.fc1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=8, out_features=4, bias=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0737, -0.2465,  0.1391, -0.1397,  0.1616, -0.0875, -0.2610,  0.3344],\n",
      "        [-0.1374, -0.0259, -0.3003, -0.2538,  0.1562, -0.1993,  0.1338, -0.0757],\n",
      "        [-0.0462,  0.3318, -0.2704,  0.3306, -0.1283, -0.0903, -0.1130,  0.2921],\n",
      "        [ 0.2102, -0.0504, -0.2849, -0.1653, -0.2552, -0.1747, -0.3002,  0.0139]],\n",
      "       requires_grad=True)\n",
      "\n",
      "Parameter containing:\n",
      "tensor([ 0.3327,  0.1590, -0.2474, -0.1727], requires_grad=True)\n",
      "\n",
      "Parameter containing:\n",
      "tensor([[ 0.1164,  0.2911, -0.2814, -0.4653],\n",
      "        [ 0.0347,  0.2670, -0.4503,  0.4388]], requires_grad=True)\n",
      "\n",
      "Parameter containing:\n",
      "tensor([-0.2028, -0.3291], requires_grad=True)\n",
      "\n",
      "Parameter containing:\n",
      "tensor([[-0.2309, -0.1969]], requires_grad=True)\n",
      "\n",
      "Parameter containing:\n",
      "tensor([0.3836], requires_grad=True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param, end='\\n\\n')\n",
    "\n",
    "# .parameters() method returns an iterator over module parameters => have to use for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight Parameter containing:\n",
      "tensor([[ 0.0835, -0.5888, -0.5067,  0.4745, -0.0378,  0.2991, -0.6782, -0.0997],\n",
      "        [-0.1608,  0.3889, -0.0752,  0.4890,  0.4044,  0.0042, -0.5556, -0.2057],\n",
      "        [ 0.2228, -0.2310,  0.6308,  0.5236, -0.3496, -0.3436,  0.4984, -0.2262],\n",
      "        [ 0.1454, -0.2981,  0.0799, -0.1087, -0.1138,  0.1765, -0.2492, -0.7047]],\n",
      "       requires_grad=True)\n",
      "\n",
      "fc1.bias Parameter containing:\n",
      "tensor([ 0.3327,  0.1590, -0.2474, -0.1727], requires_grad=True)\n",
      "\n",
      "fc2.weight Parameter containing:\n",
      "tensor([[ 0.1164,  0.2911, -0.2814, -0.4653],\n",
      "        [ 0.0347,  0.2670, -0.4503,  0.4388]], requires_grad=True)\n",
      "\n",
      "fc2.bias Parameter containing:\n",
      "tensor([-0.2028, -0.3291], requires_grad=True)\n",
      "\n",
      "fc3.weight Parameter containing:\n",
      "tensor([[-0.2309, -0.1969]], requires_grad=True)\n",
      "\n",
      "fc3.bias Parameter containing:\n",
      "tensor([0.3836], requires_grad=True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# But we don't know the name of the parameters : .named_parameters() method\n",
    "# 모델 각 층별 W, b 확인\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이제 이걸 opimizer에 넣어서 학습을 시키면 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer 가중치 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.3231,  0.2160, -0.5479, -0.2011,  0.2111,  0.1731, -0.4093, -0.6172],\n",
      "        [-0.6861,  0.3510, -0.3353, -0.0637, -0.4499,  0.1799, -0.5902,  0.0026],\n",
      "        [ 0.2835,  0.3896, -0.3162, -0.0743,  0.5827,  0.0427, -0.5057,  0.0155],\n",
      "        [-0.2339,  0.1367,  0.1956,  0.6987,  0.0144,  0.4216,  0.2146, -0.4484]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1231,  0.5636,  0.0315, -0.1863, -0.6883,  0.3614,  0.2530, -0.2425],\n",
      "        [-0.3115, -0.0725,  0.3068, -0.1292,  0.3085,  0.0371, -0.4480, -0.5644],\n",
      "        [-0.7895,  0.7087, -0.0876,  0.2714, -0.1825,  0.4090,  0.6595,  0.1761],\n",
      "        [ 0.2472,  0.5612,  0.1333, -0.3594, -0.9065, -0.3974,  0.3337, -0.2147]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Layer Weight Initialization : 세비어 알고리즘으로 초기화\n",
    "# - uniform_ : inplace와 같은 말\n",
    "print(nn.init.xavier_uniform_(model.fc1.weight))\n",
    "print(nn.init.xavier_normal_(model.fc1.weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.4559, -0.4614, -0.1921, -0.6967,  0.4317,  0.7838,  0.5788, -0.6705],\n",
      "        [-0.8409,  0.6749,  0.0622,  0.4947, -0.1938,  0.7961, -0.3015,  0.3056],\n",
      "        [ 0.0357, -0.0348, -0.7893, -0.0212, -0.0684,  0.1228, -0.4919, -0.0445],\n",
      "        [-0.2800, -0.6831,  0.0300,  0.1652, -0.8040,  0.6348, -0.2394, -0.5648]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1967,  0.1419,  0.1145, -0.0385, -0.8435,  0.6116,  0.4025, -0.0867],\n",
      "        [-0.6370, -0.1491, -0.5232,  0.1921, -0.4305, -0.2471, -0.7467, -0.0566],\n",
      "        [-0.5473, -0.5791,  0.2884, -0.5220, -0.1187, -0.5314,  0.9394, -0.6911],\n",
      "        [-0.3961,  0.9242, -0.1629, -0.2890,  0.2372,  0.4482,  0.0137,  0.0821]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# 헤 알고리즘으로 초기화 : .kaiming_uniform_() method\n",
    "print(nn.init.kaiming_uniform_(model.fc1.weight))\n",
    "print(nn.init.kaiming_normal_(model.fc1.weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "uniform_과 normal_의 차이  \n",
    ": uniform_은 균일 분포에서 랜덤하게 값을 뽑아내고, normal은 정규 분포에서 랜덤하게 값을 뽑아낸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=8, out_features=4, bias=True)\n",
      "\n",
      "Linear(in_features=4, out_features=2, bias=True)\n",
      "\n",
      "Linear(in_features=2, out_features=1, bias=True)\n",
      "\n",
      "('fc1', Linear(in_features=8, out_features=4, bias=True))\n",
      "\n",
      "('fc2', Linear(in_features=4, out_features=2, bias=True))\n",
      "\n",
      "('fc3', Linear(in_features=2, out_features=1, bias=True))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 모델 구성 모든 층 가져오기\n",
    "for child in model.children():\n",
    "    print(child, end='\\n\\n')\n",
    "    \n",
    "for child in model.named_children():    # 이름도 같이 출력\n",
    "    print(child, end='\\n\\n')            # ('fc1', Linear(in_features=8, out_features=4, bias=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "Net                                      --\n",
       "├─Linear: 1-1                            36\n",
       "├─Linear: 1-2                            10\n",
       "├─Linear: 1-3                            3\n",
       "=================================================================\n",
       "Total params: 49\n",
       "Trainable params: 49\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torchinfo로 모델 구조 확인\n",
    "from torchinfo import summary\n",
    "\n",
    "# summary(model, input_size=(1, 8))\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><hr>\n",
    "\n",
    "##### 오후 수업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 저장\n",
    "torch.save(model.state_dict(), 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=8, out_features=4, bias=True)\n",
      "  (fc2): Linear(in_features=4, out_features=2, bias=True)\n",
      "  (fc3): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# model 불러오기\n",
    "my_model = Net()\n",
    "my_model.load_state_dict(torch.load('model.pt'))\n",
    "print(my_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch_PY38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
