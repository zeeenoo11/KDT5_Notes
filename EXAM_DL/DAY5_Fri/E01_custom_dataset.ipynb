{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataSet & DataLoader 살펴보기\n",
    "- pytorch에서 배치크기만큼 데이터를 조절하기 위한 메커니즘\n",
    "- Dataset : 사용자 데이터를 기반으로 사용자 정의 클래스 작성\n",
    "- DataLoad : 지정된 Dataset에서 지정된 배치 크기만큼 피처와 타깃을 추출하여 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Load Module\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3]) 2 torch.Size([5, 1]) 2\n"
     ]
    }
   ],
   "source": [
    "# 1. Load Data\n",
    "x_data = torch.IntTensor(\n",
    "    [[10, 20, 30], [20, 30, 40], [30, 40, 50], [40, 50, 60], [50, 60, 70]]\n",
    ")\n",
    "y_data = torch.FloatTensor([[20], [30], [40], [50], [60]])\n",
    "\n",
    "print(x_data.shape, x_data.ndim, y_data.shape, y_data.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[10, 20, 30],\n",
       "         [20, 30, 40],\n",
       "         [30, 40, 50],\n",
       "         [40, 50, 60],\n",
       "         [50, 60, 70]], dtype=torch.int32),\n",
       " tensor([[20.],\n",
       "         [30.],\n",
       "         [40.],\n",
       "         [50.],\n",
       "         [60.]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Create DataSet\n",
    "# 1) TensoririsDFset 활용 : Dataset의 sub_class\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "dataset = TensorDataset(x_data, y_data)\n",
    "dataset.tensors\n",
    "\n",
    "# 주의 : x, y data의 행 번호가 맞아야 실행된다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([10, 20, 30], dtype=torch.int32), tensor([20.]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# __getitem__() 메서드 호출\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) 사용자 정의 데이터셋 생성\n",
    "# (1) Load file\n",
    "irisDF = pd.read_csv('iris.csv')\n",
    "irisDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (2) feature : numpy로 가져오기\n",
    "irisNP = np.loadtxt('iris.csv', delimiter=',', usecols=[0, 1, 2, 3], skiprows=1)\n",
    "irisNP.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3) 사용자 정의 Dataset class\n",
    "# - callback function\n",
    "class IrisDataset(Dataset):\n",
    "    def __init__(self, x_data, y_data):  # 초기화 함수\n",
    "        super().__init__()\n",
    "        x_data = x_data.values if isinstance(x_data, pd.DataFrame) else x_data  \n",
    "        y_data = y_data.values if isinstance(y_data, pd.DataFrame) else y_data\n",
    "        # : x_data, y_data가 DataFrame이면 value를 반환\n",
    "               \n",
    "        # ndarray ==> Tensor\n",
    "        self.feature = torch.FloatTensor(x_data)\n",
    "        self.target = torch.FloatTensor(y_data)\n",
    "\n",
    "    def __len__(self):  # 갯수 확인 함수\n",
    "        return self.target.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.feature[index], self.target[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'numpy.ndarray'>\n",
      "DataFrame\n",
      "ndarray\n"
     ]
    }
   ],
   "source": [
    "# check datatype\n",
    "print(\n",
    "    type(irisDF), \n",
    "    type(irisNP),\n",
    "    irisDF.__class__.__name__,\n",
    "    irisNP.__class__.__name__,\n",
    "    sep=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4) (150,)\n"
     ]
    }
   ],
   "source": [
    "# Split feature and target\n",
    "featureDF, targetDF = irisDF[irisDF.columns[:-1]], irisDF[irisDF.columns[-1]]\n",
    "print(featureDF.shape, targetDF.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "species\n",
       "0    50\n",
       "1    50\n",
       "2    50\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Categorize target\n",
    "targetDF = targetDF.replace({'setosa': 0, 'versicolor': 1, 'virginica': 2})\n",
    "targetDF.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numpy에서 차원 증가 = reshape()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "targetNP = LabelEncoder().fit_transform(targetDF)\n",
    "targetNP.shape  # 차원\n",
    "targetNP = targetNP.reshape(-1, 1)\n",
    "targetNP.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([5.1000, 3.5000, 1.4000, 0.2000]), tensor([0.])),\n",
       " sepal_length    5.1\n",
       " sepal_width     3.5\n",
       " petal_length    1.4\n",
       " petal_width     0.2\n",
       " Name: 0, dtype: float64,\n",
       " 0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋 생성\n",
    "my_dataset = IrisDataset(featureDF, targetNP)\n",
    "my_dataset[0], featureDF.iloc[0], targetDF[0]   # 첫 값을 반환\n",
    "# : dataset을 만들었을 때 해당 인덱스를 튜플로 반환, 이를 DF로 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정리 : dataset 만듦을 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>오후 수업<hr>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_ds: 105개, val_ds: 15개, test_ds: 30개\n",
      "train_ds의 Subset 속성 :\n",
      "    indices : [141, 44, 66, 56, 17, 122, 83, 75, 101, 41, 92, 98, 89, 102, 30, 90, 130, 86, 94, 12, 58, 61, 34, 24, 138, 128, 95, 124, 96, 109, 145, 115, 38, 100, 133, 33, 7, 65, 40, 125, 79, 11, 16, 60, 55, 143, 63, 74, 116, 108, 77, 68, 67, 36, 93, 1, 137, 112, 4, 139, 26, 18, 22, 47, 105, 123, 76, 87, 31, 73, 70, 37, 118, 14, 107, 127, 146, 39, 20, 48, 69, 0, 103, 23, 15, 129, 82, 6, 42, 121, 114, 5, 59, 62, 134, 21, 57, 3, 142, 136, 117, 131, 53, 10, 81]\n",
      "    dataset : <__main__.IrisDataset object at 0x000001EF06871D30>\n"
     ]
    }
   ],
   "source": [
    "# 2-3. DataSet for Training, Valuate, Test\n",
    "# 1) pytorch\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# Set rate of train, val, test\n",
    "seed = torch.Generator().manual_seed(11)\n",
    "train_ds, val_ds, test_ds = random_split(my_dataset, [0.7, 0.1, 0.2], generator=seed)\n",
    "print(\n",
    "    f\"train_ds: {len(train_ds)}개, val_ds: {len(val_ds)}개, test_ds: {len(test_ds)}개\"\n",
    ")\n",
    "print(\n",
    "    f\"\"\"train_ds의 Subset 속성 :\n",
    "    indices : {train_ds.indices}\n",
    "    dataset : {train_ds.dataset}\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. DataLoader 생성 : 학습, 검증, 평가용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 3, 6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3-1. Create DataLoader\n",
    "# - drop_last=bool : 배치 사이즈에서 남는 데이터 처리 방법 (false)\n",
    "batch = 5\n",
    "train_dl = DataLoader(train_ds, batch_size=batch)\n",
    "val_dl = DataLoader(val_ds, batch_size=batch)\n",
    "test_dl = DataLoader(test_ds, batch_size=batch)\n",
    "\n",
    "len(train_dl), len(val_dl), len(test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size : 5\n",
      "train_ds : 105개, val_ds : 15개, test_ds : 30개\n",
      "train_dl : 21개, val_dl : 3개, test_dl : 6개\n"
     ]
    }
   ],
   "source": [
    "# Iteration : Epoch당 반복 단위\n",
    "print(f'batch size : {batch}')\n",
    "print(f'train_ds : {len(train_ds)}개, val_ds : {len(val_ds)}개, test_ds : {len(test_ds)}개')\n",
    "print(f'train_dl : {len(train_dl)}개, val_dl : {len(val_dl)}개, test_dl : {len(test_dl)}개')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] feature shape : torch.Size([5, 4])\n",
      "[1] feature shape : torch.Size([5, 4])\n",
      "[2] feature shape : torch.Size([5, 4])\n",
      "[3] feature shape : torch.Size([5, 4])\n",
      "[4] feature shape : torch.Size([5, 4])\n",
      "[5] feature shape : torch.Size([5, 4])\n",
      "[6] feature shape : torch.Size([5, 4])\n",
      "[7] feature shape : torch.Size([5, 4])\n",
      "[8] feature shape : torch.Size([5, 4])\n",
      "[9] feature shape : torch.Size([5, 4])\n",
      "[10] feature shape : torch.Size([5, 4])\n",
      "[11] feature shape : torch.Size([5, 4])\n",
      "[12] feature shape : torch.Size([5, 4])\n",
      "[13] feature shape : torch.Size([5, 4])\n",
      "[14] feature shape : torch.Size([5, 4])\n",
      "[15] feature shape : torch.Size([5, 4])\n",
      "[16] feature shape : torch.Size([5, 4])\n",
      "[17] feature shape : torch.Size([5, 4])\n",
      "[18] feature shape : torch.Size([5, 4])\n",
      "[19] feature shape : torch.Size([5, 4])\n",
      "[20] feature shape : torch.Size([5, 4])\n"
     ]
    }
   ],
   "source": [
    "# Attributes of DataLoader\n",
    "for _, (feature, target) in enumerate(train_dl):\n",
    "    print(f'[{_}] feature shape : {feature.shape}')\n",
    "    # 로더에서 가져온 데이터만큼 학습 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Model 클래스 정의 : 입출력 피처 수, 층 수, 은닉 층의 노드 수 <hr>\n",
    "- 구조 설계\n",
    "1) 입력층 : 입력 => 피쳐 개수, iris는 4개\n",
    "2) 은닉층 : 맘대루\n",
    "3) 출력층 : 출력 => [분류] 타겟 클래스 갯수 [회귀] 1개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류 모델 : 내가 직접 만들어 보기\n",
    "class ClassifyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ClassifyModel, self).__init__()\n",
    "        # 모델 레이어를 정의하고 초기화\n",
    "        self.layer1 = nn.Linear(4, 10)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(10, 5)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.layer3 = nn.Linear(5, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 순전파 동작 구현\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "    \n",
    "class RegressModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RegressModule, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(4, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  모델 클래스 정의\n",
    "# 클래스명 : Classfy_Model\n",
    "class Classfy_Model(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.input_layer = nn.Linear(in_dim, 20)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.hidden_layer = nn.Linear(20, 10)\n",
    "        self.output_layer = nn.Linear(10, out_dim)\n",
    "        \n",
    "    def forward(self, x):   \n",
    "        \"\"\"\n",
    "        순방향 학습 진행 함수\n",
    "        \"\"\"\n",
    "        y = self.input_layer(x)     # W1x1+W2x2+...+Wnxn+b 20개 반환\n",
    "        self.relu(y)                # relu() 결과 20개 반환\n",
    "        y = self.hidden_layer(y)    # W1x1+W2x2+...+Wnxn+b 10개 반환\n",
    "        self.relu(y)                # relu() 10개 반환\n",
    "        y = self.output_layer(y)    # W1x1+W2x2+ ... 3개 반환\n",
    "        return y\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 학습 준비  \n",
    ": 실행 디바이스, 모델, 최적화, 손실함수, 학습 횟수, 학습함수, 평가함수, 예측함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1\n",
      "Classfy_Model(\n",
      "  (input_layer): Linear(in_features=4, out_features=20, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (hidden_layer): Linear(in_features=20, out_features=10, bias=True)\n",
      "  (output_layer): Linear(in_features=10, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 1) Set Device\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# 2) Train Counts\n",
    "EPOCHS = 50\n",
    "\n",
    "# 3) Model instance\n",
    "IN, OUT = my_dataset.feature.shape[1], my_dataset.target.shape[1]\n",
    "# 강사님 : len(np.unique(target_df))\n",
    "model = Classfy_Model(IN, OUT).to(DEVICE)\n",
    "print(IN, OUT)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Func.\n",
    "LOSS_FUNC = nn.CrossEntropyLoss().to(DEVICE)\n",
    "\n",
    "# 최적화 인스턴스\n",
    "import torch.optim as optim\n",
    "\n",
    "OPTIMIZER = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Func.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Func.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prdiction Func.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch_PY38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
