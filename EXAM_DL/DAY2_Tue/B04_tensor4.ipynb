{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor shape 변경\n",
    "- reshape(), view() : 원소 갯수가 유지됨! 기존 텐서 공유함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3]) 2\n"
     ]
    }
   ],
   "source": [
    "# 텐서 데이터 생성\n",
    "t1 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(t1.shape, t1.ndim, t1.storage_offset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [2,3] -> [3,2]로 형태 변경 : 원소는 동일하게 6개\n",
    "t1.view(3,2)    # 1차원으로 쭉 읽어가면서 새로 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1],\n",
       "         [2],\n",
       "         [3],\n",
       "         [4],\n",
       "         [5],\n",
       "         [6]]),\n",
       " tensor([[1, 2, 3, 4, 5, 6]]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [-1, ] : -1 이면 상관 안하겠단 얘기, 알아서 지정하란 뜻\n",
    "t1.view(-1, 1), t1.view(1, -1)\n",
    "\n",
    "# 오류 1: RuntimeError: shape '[4, -1]' is invalid for input of size 6\n",
    "# t1.view(4, -1) : 약수가 아니면 오류\n",
    "\n",
    "# 오류 2 : RuntimeError: only one dimension can be inferred\n",
    "# t1.view(-1, -1) : 1차원?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "# 행렬 전환 : .T\n",
    "print(t1.shape)\n",
    "t2 = t1.T\n",
    "print(t2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr> \n",
    "\n",
    ".reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .view(-1, 6) : RuntimeError: view size is not compatible with input tensor's size and stride\n",
    "# t2.view(-1, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 4, 2, 5, 3, 6]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2.reshape(-1, 6)   # .reshape은 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이유: .is_contiguous() -> \n",
    "t2.is_contiguous()  # False\n",
    "t2.reshape(-1,6).is_contiguous()    # True\n",
    "\n",
    "# 데이터 구조 차이 : ndarray는 메타 데이터를 포함한다; 아래부터 설명 시작"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서 데이터의 메모리 저장 정보, 즉 메타데이터\n",
    "- 현재 저장 형태, 검색 방향 정보, 시작 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3]) 2\n",
      "t1.storage() :\n",
      " 1\n",
      " 2\n",
      " 3\n",
      " 4\n",
      " 5\n",
      " 6\n",
      "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 6]\n",
      "t1.storage_offset() : 0\n",
      "t1.stride() : (3, 1)\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(t1.shape, t1.ndim)\n",
    "print(f't1.storage() :\\n{t1.storage()}')    # 데이터는 이렇게 1 어레이로 저장\n",
    "#  1\n",
    "#  2\n",
    "#  3\n",
    "#  4\n",
    "#  5\n",
    "#  6\n",
    "# [torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 6]\n",
    "\n",
    "print(f't1.storage_offset() : {t1.storage_offset()}')\n",
    "# t1.storage_offset() : 0   \n",
    "\n",
    "print(f't1.stride() : {t1.stride()}')\n",
    "# t1.stride() : (3, 1) => 행으로 3칸, 열로 1칸\n",
    "# 1 2 3\n",
    "# 4 5 6\n",
    "\n",
    "# => 어디까지의 기준이지?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2]) 2\n",
      "t2.storage() :\n",
      " 1\n",
      " 2\n",
      " 3\n",
      " 4\n",
      " 5\n",
      " 6\n",
      "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 6]\n",
      "t2.storage_offset() : 0\n",
      "t2.stride() : (2, 1)\n"
     ]
    }
   ],
   "source": [
    "t2 = t1.view(-1, 2)\n",
    "# 1 4\n",
    "# 2 5\n",
    "# 3 6\n",
    "\n",
    "print(t2.shape, t2.ndim)\n",
    "print(f't2.storage() :\\n{t2.storage()}')\n",
    "#  1\n",
    "#  2\n",
    "#  3\n",
    "#  4\n",
    "#  5\n",
    "#  6\n",
    "# [torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 6]\n",
    "\n",
    "print(f't2.storage_offset() : {t2.storage_offset()}')\n",
    "# t2.storage_offset() : 0   \n",
    "\n",
    "print(f't2.stride() : {t2.stride()}')   \n",
    "# t2.stride() : (2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 차원 제거/추가\n",
    "- tensor.squeeze() : 텐서에서 차원이 1인 것을 제거\n",
    "- tensor.unsqueeze(dim) : 텐서에서 차원을 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2]), 2D, 5177239208256\n",
      "torch.Size([1, 4]), 2D, 5177239208320\n",
      "torch.Size([1, 1, 4]), 3D, 5177239208448\n"
     ]
    }
   ],
   "source": [
    "# 데이터 추가\n",
    "t1 = torch.tensor([[1, 2], [3, 4]])\n",
    "t2 = torch.tensor([[1, 2, 3, 4]])\n",
    "t3 = torch.tensor([[[1, 2, 3, 4]]])\n",
    "\n",
    "print(f'{t1.shape}, {t1.ndim}D, {t1.data_ptr()}')\n",
    "print(f'{t2.shape}, {t2.ndim}D, {t2.data_ptr()}')\n",
    "print(f'{t3.shape}, {t3.ndim}D, {t3.data_ptr()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1 차원 축소 : torch.Size([2, 2]), 2D, 5177239208256\n",
      "t2 차원 축소 : torch.Size([4]), 1D, 5177239208320\n",
      "t3 차원 축소 : torch.Size([4]), 1D, 5177239208448\n",
      "t4 차원 추가 : torch.Size([1, 1, 1, 4]), 4D, 5177239208448\n"
     ]
    }
   ],
   "source": [
    "t11 = t1.squeeze()\n",
    "t22 = t2.squeeze()\n",
    "t33 = t3.squeeze()\n",
    "t44 = t3.unsqueeze(0)\n",
    "\n",
    "print(f't1 차원 축소 : {t11.shape}, {t11.ndim}D, {t11.data_ptr()}')   # 축소할 차원이 없음\n",
    "print(f't2 차원 축소 : {t22.shape}, {t22.ndim}D, {t22.data_ptr()}')   # 차원 축소됨\n",
    "print(f't3 차원 축소 : {t33.shape}, {t33.ndim}D, {t33.data_ptr()}')   # 차원은 최대한으로 축소 : 3-> 1D\n",
    "print(f't4 차원 추가 : {t44.shape}, {t44.ndim}D, {t44.data_ptr()}')   # 차원 추가, 주소는 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원소/요소 수 변경 없이 1차원 증가시키기 : torch.unsqueeze(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1 정보 : torch.Size([2, 2]), 2D, 5177239208256, (2, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f't1 정보 : {t1.shape}, {t1.ndim}D, {t1.data_ptr()}, {t1.stride()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t11 정보 : torch.Size([2, 1, 2]), 3D, 5177239208256, (2, 2, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2]],\n",
       "\n",
       "        [[3, 4]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t11 = t1.unsqueeze(1)\n",
    "print(f't11 정보 : {t11.shape}, {t11.ndim}D, {t11.data_ptr()}, {t11.stride()}') # 1열에 차원 추가\n",
    "t11 # 데이터는 들어있지않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2]],\n",
       "\n",
       "        [[3, 4]]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = t1.unsqueeze(dim=1)\n",
    "t0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor 차원/형태 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1 : torch.Size([1, 3, 2]), 3D\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor([[[1,2], [11, 22], [44, 55]]])\n",
    "print(f't1 : {t1.shape}, {t1.ndim}D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t11 : torch.Size([2, 3, 1]), 3D\n"
     ]
    }
   ],
   "source": [
    "# 2개의 차원을 변경하는 메서드\n",
    "t11 = t1.transpose(0, 2)        # 0번에 2번을 넣겠다\n",
    "print(f't11 : {t11.shape}, {t11.ndim}D')\n",
    "\n",
    "# 다차원에서 .transpose는 교환할 차원을 선택해야함 (2차원은 자동)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t22 : torch.Size([3, 2, 1]), 3D\n"
     ]
    }
   ],
   "source": [
    "# 다 섞는 친구 .permute\n",
    "t22 = t1.permute(1, 2, 0)       # 해당 인덱스를 넣음 : 첫번째에 인덱스1(=3), 두 번째에 인덱스2(=2), 세 번째에 인덱스0(=1)\n",
    "print(f't22 : {t22.shape}, {t22.ndim}D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 2]), torch.Size([1, 1, 3, 2]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 차원 추가 : None\n",
    "t1.shape, t1[None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일단 fin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch_PY38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
