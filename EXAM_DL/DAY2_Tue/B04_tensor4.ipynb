{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor shape 변경\n",
    "- reshape(), view() : 원소 갯수가 유지됨! 기존 텐서 공유함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3]) 2\n"
     ]
    }
   ],
   "source": [
    "# 텐서 데이터 생성\n",
    "t1 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(t1.shape, t1.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [2,3] -> [3,2]로 형태 변경 : 원소는 동일하게 6개\n",
    "t1.view(3,2)    # 1차원으로 쭉 읽어가면서 새로 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1],\n",
       "         [2],\n",
       "         [3],\n",
       "         [4],\n",
       "         [5],\n",
       "         [6]]),\n",
       " tensor([[1, 2, 3, 4, 5, 6]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [-1, ] : -1 이면 상관 안하겠단 얘기, 알아서 지정하란 뜻\n",
    "t1.view(-1, 1), t1.view(1, -1)\n",
    "\n",
    "# 오류 1: RuntimeError: shape '[4, -1]' is invalid for input of size 6\n",
    "# t1.view(4, -1) : 약수가 아니면 오류\n",
    "\n",
    "# 오류 2 : RuntimeError: only one dimension can be inferred\n",
    "# t1.view(-1, -1) : 1차원?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "# 행렬 전환 : .T\n",
    "print(t1.shape)\n",
    "t2 = t1.T\n",
    "print(t2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr> \n",
    "\n",
    ".reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# .view(-1, 6) : RuntimeError: view size is not compatible with input tensor's size and stride\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mt2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "# .view(-1, 6) : RuntimeError: view size is not compatible with input tensor's size and stride\n",
    "t2.view(-1, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 4, 2, 5, 3, 6]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2.reshape(-1, 6)   # .reshape은 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이유: .is_contiguous() -> \n",
    "t2.is_contiguous()  # False\n",
    "t2.reshape(-1,6).is_contiguous()    # True\n",
    "\n",
    "# 데이터 구조 차이 : ndarray는 메타 데이터를 포함한다; 아래부터 설명 시작"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서 데이터의 메모리 저장 정보, 즉 메타데이터\n",
    "- 현재 저장 형태, 검색 방향 정보, 시작 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3]) 2\n",
      "t1.storage() :\n",
      " 1\n",
      " 2\n",
      " 3\n",
      " 4\n",
      " 5\n",
      " 6\n",
      "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 6]\n",
      "t1.storage_offset() : 0\n",
      "t1.stride() : (3, 1)\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(t1.shape, t1.ndim)\n",
    "print(f't1.storage() :\\n{t1.storage()}')    # 데이터는 이렇게 1 어레이로 저장\n",
    "#  1\n",
    "#  2\n",
    "#  3\n",
    "#  4\n",
    "#  5\n",
    "#  6\n",
    "# [torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 6]\n",
    "\n",
    "print(f't1.storage_offset() : {t1.storage_offset()}')\n",
    "# t1.storage_offset() : 0   \n",
    "\n",
    "print(f't1.stride() : {t1.stride()}')\n",
    "# t1.stride() : (3, 1) => 행으로 3칸, 열로 1칸\n",
    "# 1 2 3\n",
    "# 4 5 6\n",
    "\n",
    "# => 어디까지의 기준이지?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2]) 2\n",
      "t2.storage() :\n",
      " 1\n",
      " 2\n",
      " 3\n",
      " 4\n",
      " 5\n",
      " 6\n",
      "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 6]\n",
      "t2.storage_offset() : 0\n",
      "t2.stride() : (2, 1)\n"
     ]
    }
   ],
   "source": [
    "t2 = t1.view(-1, 2)\n",
    "# 1 4\n",
    "# 2 5\n",
    "# 3 6\n",
    "\n",
    "print(t2.shape, t2.ndim)\n",
    "print(f't2.storage() :\\n{t2.storage()}')\n",
    "#  1\n",
    "#  2\n",
    "#  3\n",
    "#  4\n",
    "#  5\n",
    "#  6\n",
    "# [torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 6]\n",
    "\n",
    "print(f't2.storage_offset() : {t2.storage_offset()}')\n",
    "# t2.storage_offset() : 0   \n",
    "\n",
    "print(f't2.stride() : {t2.stride()}')   \n",
    "# t2.stride() : (2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 차원 제거/추가\n",
    "- tensor.squeeze() : 텐서에서 차원이 1인 것을 제거\n",
    "- tensor.unsqueeze(dim) : 텐서에서 차원을 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2]), 2D, 2361741345344\n",
      "torch.Size([1, 4]), 2D, 2361741345472\n",
      "torch.Size([1, 1, 4]), 3D, 2361741345536\n"
     ]
    }
   ],
   "source": [
    "# 데이터 추가\n",
    "t1 = torch.tensor([[1, 2], [3, 4]])\n",
    "t2 = torch.tensor([[1, 2, 3, 4]])\n",
    "t3 = torch.tensor([[[1, 2, 3, 4]]])\n",
    "\n",
    "print(f'{t1.shape}, {t1.ndim}D, {t1.data_ptr()}')\n",
    "print(f'{t2.shape}, {t2.ndim}D, {t2.data_ptr()}')\n",
    "print(f'{t3.shape}, {t3.ndim}D, {t3.data_ptr()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1 차원 축소 : torch.Size([2, 2]), 2D, 2361741345344\n",
      "t2 차원 축소 : torch.Size([4]), 1D, 2361741345472\n",
      "t3 차원 축소 : torch.Size([4]), 1D, 2361741345536\n",
      "t4 차원 추가 : torch.Size([1, 1, 1, 4]), 4D, 2361741345536\n"
     ]
    }
   ],
   "source": [
    "t11 = t1.squeeze()\n",
    "t22 = t2.squeeze()\n",
    "t33 = t3.squeeze()\n",
    "t44 = t3.unsqueeze(0)\n",
    "\n",
    "print(f't1 차원 축소 : {t11.shape}, {t11.ndim}D, {t11.data_ptr()}')   # 축소할 차원이 없음\n",
    "print(f't2 차원 축소 : {t22.shape}, {t22.ndim}D, {t22.data_ptr()}')   # 차원 축소됨\n",
    "print(f't3 차원 축소 : {t33.shape}, {t33.ndim}D, {t33.data_ptr()}')   # 차원은 최대한으로 축소 : 3-> 1D\n",
    "print(f't4 차원 추가 : {t44.shape}, {t44.ndim}D, {t44.data_ptr()}')   # 차원 추가, 주소는 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원소/요소 수 변경 없이 1차원 증가시키기 : torch.unsqueeze(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1 정보 : torch.Size([2, 3]), 2D, 3514625429952, (3, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f't1 정보 : {t1.shape}, {t1.ndim}D, {t1.data_ptr()}, {t1.stride()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t11 정보 : torch.Size([2, 1, 3]), 3D, 3514625429952, (3, 3, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3]],\n",
       "\n",
       "        [[4, 5, 6]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t11 = t1.unsqueeze(1)\n",
    "print(f't11 정보 : {t11.shape}, {t11.ndim}D, {t11.data_ptr()}, {t11.stride()}') # 1열에 차원 추가\n",
    "t11 # 데이터는 들어있지않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3]],\n",
       "\n",
       "        [[4, 5, 6]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = t1.unsqueeze(dim=1)\n",
    "t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch_PY38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
