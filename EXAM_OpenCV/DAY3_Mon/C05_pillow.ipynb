{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image\n",
    "import time\n",
    "file = '../DATA/angryping.jpg'\n",
    "\n",
    "# Open the image file\n",
    "img = Image.open(file)\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image format: JPEG Image mode: RGB Image size: (473, 535) Image info: {'jfif': 257, 'jfif_version': (1, 1), 'dpi': (144, 144), 'jfif_unit': 1, 'jfif_density': (144, 144), 'photoshop': {1028: b'', 1061: b'\\xd4\\x1d\\x8c\\xd9\\x8f\\x00\\xb2\\x04\\xe9\\x80\\t\\x98\\xec\\xf8B~'}, 'progressive': 1, 'progression': 1} Image palette: None\n"
     ]
    }
   ],
   "source": [
    "# Properties of the image\n",
    "print('Image format:', img.format, 'Image mode:', img.mode, 'Image size:', img.size, 'Image info:', img.info, 'Image palette:', img.palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torchvision.transforms => 인스턴스 생성 후 사용해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 535, 473]) 3\n",
      "tensor([[0.5569, 0.5569, 0.5569,  ..., 0.3725, 0.3725, 0.1843],\n",
      "        [0.5647, 0.5647, 0.5647,  ..., 0.3725, 0.3725, 0.3608],\n",
      "        [0.5725, 0.5725, 0.5725,  ..., 0.3765, 0.3765, 0.3961],\n",
      "        ...,\n",
      "        [0.1412, 0.1451, 0.1490,  ..., 0.1843, 0.1765, 0.1765],\n",
      "        [0.1882, 0.1882, 0.1882,  ..., 0.1804, 0.1608, 0.1765],\n",
      "        [0.1922, 0.1922, 0.1922,  ..., 0.1686, 0.1647, 0.1765]])\n"
     ]
    }
   ],
   "source": [
    "# 1) 인스턴스 생성\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "# 2) 인스턴스 변수 사용\n",
    "img_tensor = to_tensor(img)\n",
    "\n",
    "# 3) 변환된 이미지 텐서 확인\n",
    "print(img_tensor.shape, img_tensor.ndim)    # torch.Size([3, 535, 473]) 3\n",
    "print(img_tensor[0])    # 첫번째 채널의 모든 픽셀값 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (535, 473, 3) 3\n",
      "<class 'numpy.ndarray'> (535, 473, 3) 3\n",
      "torch.float32\n",
      "torch.Size([3, 535, 473]) 3\n",
      "torch.Size([3, 535, 473]) 3\n"
     ]
    }
   ],
   "source": [
    "# openCV\n",
    "# + BGR -> RGB : openCV는 BGR로 이미지를 읽어오기 때문에 RGB로 변환해주어야 한다.\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread(file)  # BGR\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # BGR -> RGB\n",
    "print(type(img), img.shape, img.ndim)   # <class 'numpy.ndarray'> (535, 473, 3) 3D\n",
    "print(type(img_rgb), img_rgb.shape, img_rgb.ndim)    # 얘의 차이는 없다(채널 순서만 다를 뿐)\n",
    "\n",
    "# from numpy to tensor\n",
    "img_tensor = to_tensor(img)\n",
    "img_rgb = to_tensor(img_rgb)    # BGR -> RGB\n",
    "print(img_tensor.dtype)         # torch.float32\n",
    "print(img_tensor.shape, img_tensor.ndim)    # torch.Size([3, 535, 473]) 3D\n",
    "print(img_rgb.shape, img_rgb.ndim)          # torch.Size([3, 535, 473]) 3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".Compose : 여러 변환을 연결하여 하나의 변환으로 만듦\n",
    "- transforms.Compose([변환1, 변환2, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resizing\n",
    "perprocessing = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# - 설명이 아주 많은데 정리되는 동안 리빙랩 작성 -\n",
    "# 정리 : \n",
    "# 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch_PY38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
